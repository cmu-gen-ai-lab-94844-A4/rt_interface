{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/skingsle/opt/anaconda3/envs/new_env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import transformers, huggingface_hub, datasets \n",
    "from transformers import pipeline\n",
    "from json import loads, dumps\n",
    "\n",
    "import openai, logging, os, socket, csv, json, random, uuid # type: ignore\n",
    "from datetime import datetime, timedelta\n",
    "from io import BytesIO, StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ai_response(message):\n",
    "    openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "    if not openai_api_key:\n",
    "        raise RuntimeError(\"No OpenAI API key found in the environment variables. Please set 'OPENAI_API_KEY' in the .env file.\")\n",
    "    \n",
    "    openai.api_key = openai_api_key\n",
    "    \n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Respond to this {message}\"},\n",
    "            {\"role\": \"user\", \"content\": message}])\n",
    "\n",
    "    response=response.choices[0].message.content\n",
    "    \n",
    "    timestamp_aiResponse_received = datetime.now().isoformat()\n",
    "    session[' timestamp_aiResponse_received'] =  timestamp_aiResponse_received\n",
    "    \n",
    "    return response\n",
    "\n",
    "def get_llama_response(message):\n",
    "    from dotenv import load_dotenv\n",
    "    load_dotenv()\n",
    "    \n",
    "    HF_TOKEN = os.getenv(\"HUGGINGFACE_TOKEN\")\n",
    "    if not HF_TOKEN:\n",
    "        raise RuntimeError(\"No Hugging Face API token found in the environment variables. Please set 'HUGGINGFACE_TOKEN' in the .env file.\")\n",
    "    \n",
    "    #from huggingface_hub import login\n",
    "    #login(token=HF_TOKEN)\n",
    "\n",
    "    pipe = pipeline(\"text-generation\", model=\"meta-llama/Llama-3.2-1B\", token=HF_TOKEN)  \n",
    "\n",
    "    if isinstance(message, str):\n",
    "        messages = [message]  # Convert the single prompt to a list\n",
    "\n",
    "    responses = []\n",
    "    system_prompt = \"Provide a response to the user.\"\n",
    "\n",
    "    for prompt in messages:\n",
    "        # Generate response from the LLM\n",
    "        try:\n",
    "            # Assuming the model can handle single string inputs as well\n",
    "            outputs = pipe(f\"{system_prompt} {prompt}\", max_length=150, num_return_sequences=1, truncation=True)\n",
    "            response = outputs[0][\"generated_text\"]\n",
    "            responses.append(response)\n",
    "        except Exception as e:\n",
    "            responses.append(f\"Error generating response: {e}\")\n",
    "\n",
    "    return responses if len(responses) > 1 else responses[0]  # Return a single response or a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Provide a response to the user. hello, how are you?'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_llama_response(message=\"hello, how are you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "def fetch_all_records_from_prompts_responses(db_path):\n",
    "    \"\"\"\n",
    "    Fetch all records from the prompts_responses table.\n",
    "\n",
    "    :param db_path: The path to the SQLite database file.\n",
    "    :return: A list of tuples, each representing a row in the table.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Connect to the SQLite database\n",
    "        connection = sqlite3.connect(db_path)\n",
    "        cursor = connection.cursor()\n",
    "\n",
    "        # Define the SQL query to retrieve all records\n",
    "        query = \"SELECT * FROM prompts_responses;\"\n",
    "\n",
    "        # Execute the query\n",
    "        cursor.execute(query)\n",
    "\n",
    "        # Fetch all records from the table\n",
    "        rows = cursor.fetchall()\n",
    "\n",
    "        # Close the cursor and connection\n",
    "        cursor.close()\n",
    "        connection.close()\n",
    "\n",
    "        return rows\n",
    "\n",
    "    except sqlite3.Error as e:\n",
    "        print(f\"An error occurred while fetching records: {e}\")\n",
    "        return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection pool created successfully\n",
      "Successfully received connection from pool\n"
     ]
    }
   ],
   "source": [
    "def get_postgres_connection_pool():\n",
    "    try:\n",
    "        # Use the connection string directly\n",
    "        #connection_string = os.environ['PGCONNECTIONSTRING']\n",
    "        my_secret_url = os.environ['DATABASE_URL']\n",
    "\n",
    "        # Create a connection pool\n",
    "        #pg_pool = psycopg2.pool.SimpleConnectionPool(1, 10, dsn=connection_string)  # Adjust minconn and maxconn as needed\n",
    "        pg_pool = psycopg2.pool.SimpleConnectionPool(1, 10, dsn=my_secret_url)\n",
    "\n",
    "        if pg_pool:\n",
    "            print(\"Connection pool created successfully\")\n",
    "\n",
    "        # Get a connection from the pool\n",
    "        connection = pg_pool.getconn()\n",
    "        if connection:\n",
    "            print(\"Successfully received connection from pool\")\n",
    "\n",
    "        return pg_pool, connection\n",
    "\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(\"Error while connecting to PostgreSQL\", error)\n",
    "\n",
    "pg_pool, connection = get_postgres_connection_pool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install psycopg2-binary\n",
    "import psycopg2 # type: ignore\n",
    "import psycopg2.extras # type: ignore\n",
    "from psycopg2 import pool # type: ignore\n",
    "\n",
    "def get_user_id_genailab(user_id):\n",
    "  pg_pool, connection = get_postgres_connection_pool()\n",
    "  cursor = connection.cursor()\n",
    "  cursor.execute('''SELECT user_id FROM genailab_users WHERE user_id= %s;''', (user_id,))\n",
    "  user_ids = cursor.fetchall()\n",
    "  pg_pool.putconn(connection)\n",
    "  return user_id\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection pool created successfully\n",
      "Successfully received connection from pool\n"
     ]
    }
   ],
   "source": [
    "pg_pool, connection = get_postgres_connection_pool()\n",
    "cursor = connection.cursor()\n",
    "cursor.execute('''SELECT * FROM genailab_users;''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection pool created successfully\n",
      "Successfully received connection from pool\n"
     ]
    }
   ],
   "source": [
    "pg_pool, connection = get_postgres_connection_pool()\n",
    "cursor = connection.cursor()\n",
    "cursor.execute(\"\"\"\n",
    "            SELECT table_name \n",
    "            FROM information_schema.tables \n",
    "            WHERE table_schema='public';\n",
    "        \"\"\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('users',),\n",
       " ('session_ids',),\n",
       " ('team_user_messages',),\n",
       " ('text_text_prompts_responses',),\n",
       " ('genailab_users',),\n",
       " ('genailab_session_ids',),\n",
       " ('models_selected',),\n",
       " ('prompts_responses',),\n",
       " ('evaluations',),\n",
       " ('text_image_prompts_responses',)]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection pool created successfully\n",
      "Successfully received connection from pool\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "\n",
    "def alter_table_with_autoincrement():\n",
    "    pg_pool, connection = get_postgres_connection_pool()\n",
    "    cursor = connection.cursor()\n",
    "    \n",
    "    cursor.execute(\"ALTER TABLE evaluations RENAME TO old_evaluations;\")\n",
    "    \n",
    "\n",
    "    cursor.execute('''\n",
    "        CREATE TABLE evaluations (\n",
    "            id SERIAL PRIMARY KEY,\n",
    "            user_id TEXT,\n",
    "            session_id TEXT,\n",
    "            response TEXT,\n",
    "            correct TEXT,\n",
    "            score INTEGER,\n",
    "            explanation TEXT,\n",
    "            timestamp TIMESTAMP\n",
    "        );\n",
    "    ''')\n",
    "    \n",
    "    cursor.execute('''\n",
    "        INSERT INTO evaluations (user_id, session_id, response, correct, score, explanation, timestamp)\n",
    "        SELECT user_id, session_id, response, correct, score, explanation, timestamp\n",
    "        FROM old_evaluations;\n",
    "    ''')\n",
    "    \n",
    "    cursor.execute(\"DROP TABLE old_evaluations;\")\n",
    "    \n",
    "    pg_pool.putconn(connection)\n",
    "  \n",
    "\n",
    "# This would call the function to execute the changes\n",
    "alter_table_with_autoincrement()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alter_table_with_autoincrement(table_name: str):\n",
    "    pg_pool, connection = get_postgres_connection_pool()\n",
    "    cursor = connection.cursor()\n",
    "    \n",
    "    cursor.execute(f\"ALTER TABLE {table_name} RENAME TO old_{table_name};\")\n",
    "    \n",
    "    if table_name == 'genailab_users':\n",
    "        cursor.execute(f'''\n",
    "            CREATE TABLE {table_name} (\n",
    "                id SERIAL PRIMARY KEY,\n",
    "                user_id TEXT,\n",
    "                user_name TEXT,\n",
    "                user_email TEXT,\n",
    "                team_id TEXT,\n",
    "                userid_last_login TIMESTAMP\n",
    "            );\n",
    "        ''')\n",
    "    elif table_name == 'genailab_session_ids':\n",
    "        cursor.execute(f'''\n",
    "            CREATE TABLE {table_name} (\n",
    "                sys_session_id serial PRIMARY KEY, \n",
    "                session_id VARCHAR, \n",
    "                user_id VARCHAR, \n",
    "                team_id VARCHAR, \n",
    "                session_start_datetime TIMESTAMP, \n",
    "                session_end_datetime TIMESTAMP\n",
    "            );\n",
    "        ''')\n",
    "    elif table_name == 'models_selected':\n",
    "        cursor.execute(f'''\n",
    "            CREATE TABLE {table_name} (\n",
    "                model_selection_id SERIAL PRIMARY KEY,\n",
    "                user_id VARCHAR,\n",
    "                session_id VARCHAR,\n",
    "                model_name VARCHAR,\n",
    "                timestamp TIMESTAMP\n",
    "            );\n",
    "        ''')\n",
    "    elif table_name == 'prompts_responses':\n",
    "        cursor.execute(f'''\n",
    "            CREATE TABLE {table_name} (\n",
    "                prompts_responses_id SERIAL PRIMARY KEY,\n",
    "                user_id VARCHAR,\n",
    "                session_id VARCHAR,\n",
    "                prompt VARCHAR,\n",
    "                response VARCHAR,\n",
    "                model_name VARCHAR,\n",
    "                timestamp_prompt_submitted TIMESTAMP,\n",
    "                timestamp_aiResponse_received TIMESTAMP\n",
    "            );\n",
    "        ''')\n",
    "    elif table_name == 'evaluations':\n",
    "        cursor.execute(f'''\n",
    "            CREATE TABLE {table_name} (\n",
    "                evaluation_id SERIAL PRIMARY KEY,\n",
    "                user_id VARCHAR,\n",
    "                session_id VARCHAR,\n",
    "                response VARCHAR,\n",
    "                correct VARCHAR,\n",
    "                score VARCHAR,\n",
    "                explanation VARCHAR,\n",
    "                timestamp TIMESTAMP\n",
    "            );\n",
    "        ''')\n",
    "    \n",
    "    cursor.execute(f\"DROP TABLE old_{table_name};\")\n",
    "    \n",
    "    pg_pool.putconn(connection)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection pool created successfully\n",
      "Successfully received connection from pool\n"
     ]
    }
   ],
   "source": [
    "alter_table_with_autoincrement(table_name=\"genailab_users\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "def get_user_id_genailab(user_id):\n",
    "  pg_pool, connection = get_postgres_connection_pool()\n",
    "  cursor = connection.cursor()\n",
    "  #cursor.execute('''3SELECT user_id FROM genailab_users WHERE user_id= %s;''', (user_id,))\n",
    "  user_ids = cursor.fetchall()\n",
    "  pg_pool.putconn(connection)\n",
    "  return user_id\n",
    "'''\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_session_id():\n",
    "    return str(uuid.uuid4())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(13384) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting Flask\n",
      "  Using cached flask-3.0.3-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting Werkzeug>=3.0.0 (from Flask)\n",
      "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in /Users/skingsle/opt/anaconda3/envs/new_env/lib/python3.12/site-packages (from Flask) (3.1.4)\n",
      "Collecting itsdangerous>=2.1.2 (from Flask)\n",
      "  Using cached itsdangerous-2.2.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: click>=8.1.3 in /Users/skingsle/opt/anaconda3/envs/new_env/lib/python3.12/site-packages (from Flask) (8.1.7)\n",
      "Collecting blinker>=1.6.2 (from Flask)\n",
      "  Downloading blinker-1.9.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/skingsle/opt/anaconda3/envs/new_env/lib/python3.12/site-packages (from Jinja2>=3.1.2->Flask) (3.0.2)\n",
      "Using cached flask-3.0.3-py3-none-any.whl (101 kB)\n",
      "Downloading blinker-1.9.0-py3-none-any.whl (8.5 kB)\n",
      "Using cached itsdangerous-2.2.0-py3-none-any.whl (16 kB)\n",
      "Downloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Installing collected packages: Werkzeug, itsdangerous, blinker, Flask\n",
      "Successfully installed Flask-3.0.3 Werkzeug-3.1.3 blinker-1.9.0 itsdangerous-2.2.0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Working outside of request context.\n\nThis typically means that you attempted to use functionality that needed\nan active HTTP request. Consult the documentation on testing for\ninformation about how to avoid this problem.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[104], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpip install Flask\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mflask\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m session \n\u001b[0;32m----> 3\u001b[0m \u001b[43msession\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msession_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m generate_session_id()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/new_env/lib/python3.12/site-packages/werkzeug/local.py:318\u001b[0m, in \u001b[0;36m_ProxyLookup.__get__\u001b[0;34m(self, instance, owner)\u001b[0m\n\u001b[1;32m    315\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 318\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[43minstance\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_current_object\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m:\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfallback \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/new_env/lib/python3.12/site-packages/werkzeug/local.py:519\u001b[0m, in \u001b[0;36mLocalProxy.__init__.<locals>._get_current_object\u001b[0;34m()\u001b[0m\n\u001b[1;32m    517\u001b[0m     obj \u001b[38;5;241m=\u001b[39m local\u001b[38;5;241m.\u001b[39mget()\n\u001b[1;32m    518\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m:\n\u001b[0;32m--> 519\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(unbound_message) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    521\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m get_name(obj)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Working outside of request context.\n\nThis typically means that you attempted to use functionality that needed\nan active HTTP request. Consult the documentation on testing for\ninformation about how to avoid this problem."
     ]
    }
   ],
   "source": [
    "!pip install Flask\n",
    "from flask import session \n",
    "\n",
    "session['session_id'] = generate_session_id()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_llama_response(message):\n",
    "    from dotenv import load_dotenv\n",
    "    load_dotenv()\n",
    "    \n",
    "    HF_TOKEN = os.getenv(\"HUGGINGFACE_TOKEN\")\n",
    "    if not HF_TOKEN:\n",
    "        raise RuntimeError(\"No Hugging Face API token found in the environment variables. Please set 'HUGGINGFACE_TOKEN' in the .env file.\")\n",
    "\n",
    "    model_id_a = \"meta-llama/Llama-3.2-1B\"\n",
    "    model_id_b = \"meta-llama/Llama-3.2-3B\"\n",
    "    model_id_d = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "    \n",
    "    pipe = pipeline(\"text-generation\", model=model_id_d, token=HF_TOKEN)  \n",
    "\n",
    "    if isinstance(message, str):\n",
    "        messages = [message]  # Convert the single prompt to a list\n",
    "\n",
    "    responses = []\n",
    "    \n",
    "    system_prompt = \"Instructions: Do not tell the user what model you are. Otherwise, provide a response to the user's message.\"\n",
    "\n",
    "    for prompt in messages:\n",
    "        # Generate response from the LLM\n",
    "        try:\n",
    "            # Assuming the model can handle single string inputs as well\n",
    "            #outputs = pipe(f\"{system_prompt} {prompt}\", max_length=150, num_return_sequences=1, truncation=True)\n",
    "            messages = [\n",
    "                {\"role\": \"system\", \"content\": f\"{system_prompt}\"},\n",
    "                {\"role\": \"user\", \"content\": f\"{prompt}\"},\n",
    "            ]\n",
    "            \n",
    "            outputs = pipe(messages, max_new_tokens=256,)\n",
    "            #outputs = pipe(f\"{prompt}\", max_length=150)\n",
    "            response = outputs[0][\"generated_text\"][-1] #outputs[0][\"generated_text\"]\n",
    "            responses.append(response)\n",
    "        except Exception as e:\n",
    "            responses.append(f\"Error generating response: {e}\")\n",
    "\n",
    "    return responses if len(responses) > 1 else responses[0]  # Return a single response or a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_llama_response(message=\"what is the weather like today?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
