{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/skingsle/opt/anaconda3/envs/new_env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import transformers, huggingface_hub, datasets \n",
    "from transformers import pipeline\n",
    "from json import loads, dumps\n",
    "\n",
    "import openai, logging, os, socket, csv, json, random, uuid # type: ignore\n",
    "from datetime import datetime, timedelta\n",
    "from io import BytesIO, StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ai_response(message):\n",
    "    openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "    if not openai_api_key:\n",
    "        raise RuntimeError(\"No OpenAI API key found in the environment variables. Please set 'OPENAI_API_KEY' in the .env file.\")\n",
    "    \n",
    "    openai.api_key = openai_api_key\n",
    "    \n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Respond to this {message}\"},\n",
    "            {\"role\": \"user\", \"content\": message}])\n",
    "\n",
    "    response=response.choices[0].message.content\n",
    "    \n",
    "    timestamp_aiResponse_received = datetime.now().isoformat()\n",
    "    session[' timestamp_aiResponse_received'] =  timestamp_aiResponse_received\n",
    "    \n",
    "    return response\n",
    "\n",
    "def get_llama_response(message):\n",
    "    from dotenv import load_dotenv\n",
    "    load_dotenv()\n",
    "    \n",
    "    HF_TOKEN = os.getenv(\"HUGGINGFACE_TOKEN\")\n",
    "    if not HF_TOKEN:\n",
    "        raise RuntimeError(\"No Hugging Face API token found in the environment variables. Please set 'HUGGINGFACE_TOKEN' in the .env file.\")\n",
    "    \n",
    "    #from huggingface_hub import login\n",
    "    #login(token=HF_TOKEN)\n",
    "\n",
    "    pipe = pipeline(\"text-generation\", model=\"meta-llama/Llama-3.2-1B\", token=HF_TOKEN)  \n",
    "\n",
    "    if isinstance(message, str):\n",
    "        messages = [message]  # Convert the single prompt to a list\n",
    "\n",
    "    responses = []\n",
    "    system_prompt = \"Provide a response to the user.\"\n",
    "\n",
    "    for prompt in messages:\n",
    "        # Generate response from the LLM\n",
    "        try:\n",
    "            # Assuming the model can handle single string inputs as well\n",
    "            outputs = pipe(f\"{system_prompt} {prompt}\", max_length=150, num_return_sequences=1, truncation=True)\n",
    "            response = outputs[0][\"generated_text\"]\n",
    "            responses.append(response)\n",
    "        except Exception as e:\n",
    "            responses.append(f\"Error generating response: {e}\")\n",
    "\n",
    "    return responses if len(responses) > 1 else responses[0]  # Return a single response or a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Provide a response to the user. hello, how are you?'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_llama_response(message=\"hello, how are you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "def fetch_all_records_from_prompts_responses(db_path):\n",
    "    \"\"\"\n",
    "    Fetch all records from the prompts_responses table.\n",
    "\n",
    "    :param db_path: The path to the SQLite database file.\n",
    "    :return: A list of tuples, each representing a row in the table.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Connect to the SQLite database\n",
    "        connection = sqlite3.connect(db_path)\n",
    "        cursor = connection.cursor()\n",
    "\n",
    "        # Define the SQL query to retrieve all records\n",
    "        query = \"SELECT * FROM prompts_responses;\"\n",
    "\n",
    "        # Execute the query\n",
    "        cursor.execute(query)\n",
    "\n",
    "        # Fetch all records from the table\n",
    "        rows = cursor.fetchall()\n",
    "\n",
    "        # Close the cursor and connection\n",
    "        cursor.close()\n",
    "        connection.close()\n",
    "\n",
    "        return rows\n",
    "\n",
    "    except sqlite3.Error as e:\n",
    "        print(f\"An error occurred while fetching records: {e}\")\n",
    "        return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection pool created successfully\n",
      "Successfully received connection from pool\n"
     ]
    }
   ],
   "source": [
    "def get_postgres_connection_pool():\n",
    "    try:\n",
    "        # Use the connection string directly\n",
    "        #connection_string = os.environ['PGCONNECTIONSTRING']\n",
    "        my_secret_url = os.environ['DATABASE_URL']\n",
    "\n",
    "        # Create a connection pool\n",
    "        #pg_pool = psycopg2.pool.SimpleConnectionPool(1, 10, dsn=connection_string)  # Adjust minconn and maxconn as needed\n",
    "        pg_pool = psycopg2.pool.SimpleConnectionPool(1, 10, dsn=my_secret_url)\n",
    "\n",
    "        if pg_pool:\n",
    "            print(\"Connection pool created successfully\")\n",
    "\n",
    "        # Get a connection from the pool\n",
    "        connection = pg_pool.getconn()\n",
    "        if connection:\n",
    "            print(\"Successfully received connection from pool\")\n",
    "\n",
    "        return pg_pool, connection\n",
    "\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(\"Error while connecting to PostgreSQL\", error)\n",
    "\n",
    "pg_pool, connection = get_postgres_connection_pool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install psycopg2-binary\n",
    "import psycopg2 # type: ignore\n",
    "import psycopg2.extras # type: ignore\n",
    "from psycopg2 import pool # type: ignore\n",
    "\n",
    "def get_user_id_genailab(user_id):\n",
    "  pg_pool, connection = get_postgres_connection_pool()\n",
    "  cursor = connection.cursor()\n",
    "  cursor.execute('''SELECT user_id FROM genailab_users WHERE user_id= %s;''', (user_id,))\n",
    "  user_ids = cursor.fetchall()\n",
    "  pg_pool.putconn(connection)\n",
    "  return user_id\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection pool created successfully\n",
      "Successfully received connection from pool\n"
     ]
    }
   ],
   "source": [
    "pg_pool, connection = get_postgres_connection_pool()\n",
    "cursor = connection.cursor()\n",
    "cursor.execute('''SELECT * FROM genailab_users;''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection pool created successfully\n",
      "Successfully received connection from pool\n"
     ]
    }
   ],
   "source": [
    "pg_pool, connection = get_postgres_connection_pool()\n",
    "cursor = connection.cursor()\n",
    "cursor.execute(\"\"\"\n",
    "            SELECT table_name \n",
    "            FROM information_schema.tables \n",
    "            WHERE table_schema='public';\n",
    "        \"\"\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('users',),\n",
       " ('session_ids',),\n",
       " ('team_user_messages',),\n",
       " ('text_text_prompts_responses',),\n",
       " ('genailab_users',),\n",
       " ('genailab_session_ids',),\n",
       " ('models_selected',),\n",
       " ('prompts_responses',),\n",
       " ('evaluations',),\n",
       " ('text_image_prompts_responses',)]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection pool created successfully\n",
      "Successfully received connection from pool\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "\n",
    "def alter_table_with_autoincrement():\n",
    "    pg_pool, connection = get_postgres_connection_pool()\n",
    "    cursor = connection.cursor()\n",
    "    \n",
    "    cursor.execute(\"ALTER TABLE evaluations RENAME TO old_evaluations;\")\n",
    "    \n",
    "\n",
    "    cursor.execute('''\n",
    "        CREATE TABLE evaluations (\n",
    "            id SERIAL PRIMARY KEY,\n",
    "            user_id TEXT,\n",
    "            session_id TEXT,\n",
    "            response TEXT,\n",
    "            correct TEXT,\n",
    "            score INTEGER,\n",
    "            explanation TEXT,\n",
    "            timestamp TIMESTAMP\n",
    "        );\n",
    "    ''')\n",
    "    \n",
    "    cursor.execute('''\n",
    "        INSERT INTO evaluations (user_id, session_id, response, correct, score, explanation, timestamp)\n",
    "        SELECT user_id, session_id, response, correct, score, explanation, timestamp\n",
    "        FROM old_evaluations;\n",
    "    ''')\n",
    "    \n",
    "    cursor.execute(\"DROP TABLE old_evaluations;\")\n",
    "    \n",
    "    pg_pool.putconn(connection)\n",
    "  \n",
    "\n",
    "# This would call the function to execute the changes\n",
    "alter_table_with_autoincrement()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alter_table_with_autoincrement(table_name: str):\n",
    "    pg_pool, connection = get_postgres_connection_pool()\n",
    "    cursor = connection.cursor()\n",
    "    \n",
    "    cursor.execute(f\"ALTER TABLE {table_name} RENAME TO old_{table_name};\")\n",
    "    \n",
    "    if table_name == 'genailab_users':\n",
    "        cursor.execute(f'''\n",
    "            CREATE TABLE {table_name} (\n",
    "                id SERIAL PRIMARY KEY,\n",
    "                user_id TEXT,\n",
    "                session_id VARCHAR,\n",
    "                user_name TEXT,\n",
    "                user_email TEXT,\n",
    "                team_id TEXT,\n",
    "                userid_last_login TIMESTAMP\n",
    "            );\n",
    "        ''')\n",
    "    elif table_name == 'genailab_session_ids':\n",
    "        cursor.execute(f'''\n",
    "            CREATE TABLE {table_name} (\n",
    "                sys_session_id serial PRIMARY KEY, \n",
    "                session_id VARCHAR, \n",
    "                user_id VARCHAR, \n",
    "                team_id VARCHAR, \n",
    "                session_start_datetime TIMESTAMP, \n",
    "                session_end_datetime TIMESTAMP\n",
    "            );\n",
    "        ''')\n",
    "    elif table_name == 'models_selected':\n",
    "        cursor.execute(f'''\n",
    "            CREATE TABLE {table_name} (\n",
    "                model_selection_id SERIAL PRIMARY KEY,\n",
    "                user_id VARCHAR,\n",
    "                session_id VARCHAR,\n",
    "                model_name VARCHAR,\n",
    "                timestamp TIMESTAMP\n",
    "            );\n",
    "        ''')\n",
    "    elif table_name == 'prompts_responses':\n",
    "        cursor.execute(f'''\n",
    "            CREATE TABLE {table_name} (\n",
    "                prompts_responses_id SERIAL PRIMARY KEY,\n",
    "                user_id VARCHAR,\n",
    "                session_id VARCHAR,\n",
    "                prompt VARCHAR,\n",
    "                response VARCHAR,\n",
    "                model_name VARCHAR,\n",
    "                timestamp_prompt_submitted TIMESTAMP,\n",
    "                timestamp_aiResponse_received TIMESTAMP\n",
    "            );\n",
    "        ''')\n",
    "    elif table_name == 'evaluations':\n",
    "        cursor.execute(f'''\n",
    "            CREATE TABLE {table_name} (\n",
    "                evaluation_id SERIAL PRIMARY KEY,\n",
    "                user_id VARCHAR,\n",
    "                session_id VARCHAR,\n",
    "                response VARCHAR,\n",
    "                correct VARCHAR,\n",
    "                score VARCHAR,\n",
    "                explanation VARCHAR,\n",
    "                timestamp TIMESTAMP\n",
    "            );\n",
    "        ''')\n",
    "    \n",
    "    cursor.execute(f\"DROP TABLE old_{table_name};\")\n",
    "    \n",
    "    pg_pool.putconn(connection)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection pool created successfully\n",
      "Successfully received connection from pool\n"
     ]
    }
   ],
   "source": [
    "alter_table_with_autoincrement(table_name=\"genailab_users\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_llama_response(message):\n",
    "    from dotenv import load_dotenv\n",
    "    load_dotenv()\n",
    "    \n",
    "    HF_TOKEN = os.getenv(\"HUGGINGFACE_TOKEN\")\n",
    "    if not HF_TOKEN:\n",
    "        raise RuntimeError(\"No Hugging Face API token found in the environment variables. Please set 'HUGGINGFACE_TOKEN' in the .env file.\")\n",
    "\n",
    "    model_id_a = \"meta-llama/Llama-3.2-1B\"\n",
    "    model_id_b = \"meta-llama/Llama-3.2-3B\"\n",
    "    model_id_d = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "    \n",
    "    pipe = pipeline(\"text-generation\", model=model_id_d, token=HF_TOKEN)  \n",
    "\n",
    "    if isinstance(message, str):\n",
    "        messages = [message]  # Convert the single prompt to a list\n",
    "\n",
    "    responses = []\n",
    "    \n",
    "    system_prompt = \"Instructions: Do not tell the user what model you are. Otherwise, provide a response to the user's message.\"\n",
    "\n",
    "    for prompt in messages:\n",
    "        # Generate response from the LLM\n",
    "        try:\n",
    "            # Assuming the model can handle single string inputs as well\n",
    "            #outputs = pipe(f\"{system_prompt} {prompt}\", max_length=150, num_return_sequences=1, truncation=True)\n",
    "            messages = [\n",
    "                {\"role\": \"system\", \"content\": f\"{system_prompt}\"},\n",
    "                {\"role\": \"user\", \"content\": f\"{prompt}\"},\n",
    "            ]\n",
    "            \n",
    "            outputs = pipe(messages, max_new_tokens=256,)\n",
    "            #outputs = pipe(f\"{prompt}\", max_length=150)\n",
    "            response = outputs[0][\"generated_text\"][-1] #outputs[0][\"generated_text\"]\n",
    "            responses.append(response)\n",
    "        except Exception as e:\n",
    "            responses.append(f\"Error generating response: {e}\")\n",
    "\n",
    "    return responses if len(responses) > 1 else responses[0]  # Return a single response or a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_llama_response(message=\"what is the weather like today?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
